{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79adf0f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-\\amily:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Data Leakage\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC June 2023\n",
    "<p>Phase 3</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f0752b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Obejective\n",
    "- Explain data leakage\n",
    "- **Explain** the bias-variance tradeoff and the correlative notions of underfit and overfit models\n",
    "- Explain the notion of \"validation data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3481ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0406274",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Data Leakage\n",
    "- When information not generally available/used at prediction time contaminates the modeling training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2745c741",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src = \"Images/despair.jpg\" width = 350 /></center>\n",
    "<center> The despair of realizing you have a data leak.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef438d5b",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Leads to overconfident estimates of model performance during the validation and testing phases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9a0528",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Bad performance after model deployment in production.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a1253",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/despair.jpg\" width = 350 /></center>\n",
    "<center> My overlords are upset.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345361c3",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src = \"Images/despair.jpg\" width = 350 /></center>\n",
    "<center> I have spent all night trying to find the data leak.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b41a8f",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/despair.jpg\" width = 350 /></center>\n",
    "<center> What is the nature of my leak?</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de0470",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src = \"Images/despair.jpg\" width = 350 /></center>\n",
    "<center> Where is it??</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f36cad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Diagnosing a data leak can be subtle business:\n",
    "- Understanding different types of leak\n",
    "- Where in the process they can be accidentally introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a46010c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Training leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5016522a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Fitting and applying transformations **before** train-test(hold out) splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e727b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = \"Images/training_testing.png\" width = 500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a77892",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Why is this bad?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4dbf91",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Applying transformation to training set:\n",
    "- contains information from test set (contained in fitted attributes of Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ba2d29",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Contaminated training set.\n",
    "- Model has inadvertently trained on information you are trying to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64622b7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### You can introduce it by accident on really innocuous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74512a3",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "titanic_df = pd.read_csv('Data/titanic.csv').drop(columns = ['Cabin'])\n",
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dc7e0f",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's impute those NaNs in age with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e6cdad",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# impute with the mean\n",
    "titanic_df['Age'] = titanic_df['Age'].fillna(titanic_df['Age'].mean())\n",
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec2d0dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bam. You just introduced data leakage.\n",
    "- imputed with statistics of entire dataset before train-test split.\n",
    "- Statistics of train in test and vice-versa.\n",
    "- Whether impact is significant will depend on data and model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0928e1a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Leakage between train and true test can be a truly costly mistake:\n",
    "- You'll only figure it out after you've deployed\n",
    "- Made suboptimal predictions:\n",
    "    - incorrectly recommending inventory changes to increase sales\n",
    "    - or *much* worse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802a2a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Other types of data leakage: Feature leakage\n",
    "\n",
    "Dependent on how the data/features were collected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d54c5",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images\\data_leakage_predcontam.png\" width = 800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2214fef1",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Predicting whether we should approve a loan or not.\n",
    "- Have database of current lendees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b43b48",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Features include:\n",
    "    - Salary information at time of loan approval\n",
    "    - Pre-loan bankruptcy history\n",
    "    - FICO score\n",
    "    - Listed occupation\n",
    "    - Monthly interest payments.\n",
    "    - Bank balance across accounts.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72129b8",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**What's the problem here?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e60ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Possibly conflating information from *after* prediction with properties before prediction.\n",
    "- Features from **after** prediction potentially affected by target.\n",
    "- Our target is now leaking into the way we trained our model.\n",
    "- Features *before* and *after* approval may not be drawn from same distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf4233",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**These sources of feature leakage can be very subtle**\n",
    "- Understanding of the data collection process and data definitions is critical here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb232c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Case Study**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef98128a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Predict sale price of a given home."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95842b36",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Size of the house (in square meters)\n",
    "- Average sales price of homes in the same neighborhood\n",
    "- Latitude and longitude of the house\n",
    "- Whether the house has a basement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb4a31",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Is there a source of potential data leakage? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877275d2",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Depends on whether the average includes the sales prices including given sale or before it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225f603a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Another Case Study**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e06ef",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Want to predict rate of infection during surgery based on:\n",
    "- patient specific factors (immuno-history, etc.)\n",
    "- environmental factors (hospital cleanliness inspections, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30cd6f",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Your idea: include surgeon as a factor.\n",
    "\n",
    "1. Take all surgeries by each surgeon and calculate the infection rate among those surgeons.\n",
    "2. For each patient in the data, find out who the surgeon was and plug in that surgeon's average infection rate as a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3011d941",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Potentially introduces both target leakage and train-test leak:\n",
    "\n",
    "- Target leakage: if given patient's outcome contributes to the infection rate for his surgeon. \n",
    "- Using target to calculate feature.\n",
    "- Then using this feature to predict target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e85383e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can avoid by using:\n",
    "- Surgeon's infection rate for only surgeries before the patient we are predicting for.\n",
    "- Tricky, for sure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eaffbc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Train-test contamination problem if you calculate this using all surgeries a surgeon performed\n",
    "- Including those from the test-set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffdd81a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Are you tearing your hair out? Good. You now understand data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797ec96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c389b4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In general all preprocessing steps are subject to the same dangers here. Consider the preprocessing step of one-hot-encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a96ca",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gun_poll = pd.read_csv('data/guns-polls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dda9b9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gun_poll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e333af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "gun_poll['Pollster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885041a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now if I were to fit a one-hot encoder to the whole `Pollster` column here, the encoder would learn all the categories. But I need to prepare myself for the real-world possibility that unfamiliar categories may show up in future records. Let's explore this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f1769",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# First I'll do a split\n",
    "X_train, X_test = train_test_split(gun_poll, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8182b2e9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's suppose now that I fit a `OneHotEncoder` to the `Pollster` column in my training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95c1beb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Exercise\n",
    "Fit an encoder to the `Pollster` column of the training data and then check to see which categories are represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6384469a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2425f455",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "\n",
    "``` python\n",
    "to_be_dummied = X_train[['Pollster']]\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(to_be_dummied)\n",
    "## So what categories do we have?\n",
    "ohe.get_feature_names_out()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459e3584",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll want to transform both train and test after we've fitted the encoder to the train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb803428",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_to_be_dummied = X_test[['Pollster']]\n",
    "\n",
    "ohe.transform(to_be_dummied)\n",
    "ohe.transform(test_to_be_dummied)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f7d986",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are categories in the testing data that don't appear in the training data! What should \n",
    "we do about that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b65cc9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Approaches\n",
    "- **Strategy 1**: Divide up the categories proportionally when we do our train_test_split. If we're using `sklearn`'s tool, that means taking advantage of the `stratify` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea26d734",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "new_X_train, new_X_test = train_test_split(gun_poll,\n",
    "                                           stratify=gun_poll['Pollster'],\n",
    "                                           random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e9f67",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Unfortunately, in this case, we can't use this since some categories have only a single member."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d96858",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Strategy 2**: Drop the categories with very few representatives.\n",
    "\n",
    "In the present case, let's try dropping the single-member categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf5102",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vc = gun_poll['Pollster'].value_counts()\n",
    "vc_only_1 = vc[vc == 1]\n",
    "bad_cols = vc_only_1.index\n",
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165faf3d",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bad_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5491db86",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "gun_poll['Pollster'] = gun_poll['Pollster'].map(lambda x: np.nan if x in bad_cols else x)\n",
    "gun_poll = gun_poll.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c0a12d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gun_poll['Pollster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741e4547",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We could now split this carefully so that new categories don't show up in the testing data. In fact, now we can try the stratified split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81db6a6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train3, X_test3 = train_test_split(gun_poll,\n",
    "                                     stratify=gun_poll['Pollster'],\n",
    "                                     test_size=0.3,\n",
    "                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1a198",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train3['Pollster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b5ec65",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_test3['Pollster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2447007",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now every category that appears in the test data appears also in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e07626",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Strategy 3**: Adjust the settings on the one-hot-encoder.\n",
    "\n",
    "For `sklearn`'s tool, we'll tweak the `handle_unknown` parameter:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0658eec0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Exericse\n",
    "Fit a new encoder to our training data column that won't break when we try to use it to transform the test data. And then use the encoder to transform both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b262050",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7066852",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "    \n",
    "```python\n",
    "ohe2 = OneHotEncoder(handle_unknown='ignore')\n",
    "ohe2.fit(to_be_dummied)\n",
    "test_to_be_dummied = X_test[['Pollster']]\n",
    "ohe2.transform(to_be_dummied)\n",
    "ohe2.transform(test_to_be_dummied)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f0cc21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "t = pd.DataFrame(ohe2.transform(test_to_be_dummied).todense(), columns = ohe2.get_feature_names_out())\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca6b8ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea98ba2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can break up how the model makes mistakes (the error) by saying there are three parts:\n",
    "\n",
    "- Error inherent in the data (noise): **irreducible error**\n",
    "- Error from not capturing signal (too simple): **bias**\n",
    "- Error from \"modeling noise\", i.e. capturing patterns in the data that don't generalize well (too complex): **variance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb0574f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5554a4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**High-bias** algorithms tend to be less complex, with simple or rigid underlying structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc33a0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](images/noisy-sine-linear.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c161e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "+ They train models that are consistent, but inaccurate on average.\n",
    "+ These include linear or parametric algorithms such as regression and naive Bayes.\n",
    "+ The following sorts of difficulties could lead to high bias:\n",
    "  - We did not include the correct predictors\n",
    "  - We did not take interactions into account\n",
    "  - We missed a non-linear (polynomial) relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f51d7a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "      \n",
    "High-bias models are generally **underfit**: The models have not picked up enough of the signal in the data. And so even though they may be consistent, they don't perform particularly well on the initial data, and so they will be consistently inaccurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec27153",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb43c58a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On the other hand, **high-variance** algorithms tend to be more complex, with flexible underlying structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d9b95",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"images/noisy-sine-decision-tree.png\"  width = 800/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402cb5bc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "+ They train models that are accurate on average, but inconsistent.\n",
    "+ These include non-linear or non-parametric algorithms such as decision trees and nearest-neighbor models.\n",
    "+ The following sorts of difficulties could lead to high variance:\n",
    "  - We included an unreasonably large number of predictors;\n",
    "  - We created new features by squaring and cubing each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e84ae5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "High variance models are **overfit**: The models have picked up on the noise as well as the signal in the data. And so even though they may perform well on the initial data, they will be inconsistently accurate on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2c4269",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Balancing Bias and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36286234",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "While we build our models, we have to keep this relationship in mind.  If we build complex models, we risk overfitting our models.  Their predictions will vary greatly when introduced to new data.  If our models are too simple, the predictions as a whole will be inaccurate.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b793425",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](images/noisy-sine-third-order-polynomial.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdba225",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bias: \n",
    "- when model not complex enough\n",
    "- feature space not adequately rich enough to explain target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f24baa",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Variance: \n",
    "\n",
    "- model/weights: large fluctuations about true model given different train sets\n",
    "\n",
    "- High $ \\mathrm{Var}[\\textbf{w}] $ over realization of training sets\n",
    "\n",
    "- High fluctuation in MAE over test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860efcd",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The bulls-eye diagrams of fitting model to different training set realizations:\n",
    "<center><img src = \"images/biasvar_bullseye.png\" width = 400/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b50399e",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Each dot is a model:\n",
    "- Bulls-eye: the *true* model (generating mean of $y$ given $X$ in the population) \n",
    "- Each dot: models trained on different samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb2a7d6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Our goal**: lowering bias and variance in training predictive models\n",
    "\n",
    "but the two often at odds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398bb014",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Multicollinearity\n",
    "Have to grapple with these issues when constructing linear models with multicollinear features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1194921",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We talked about this way back. But how does it increase Var[$\\textbf{w}$]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da55d1a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "WHO_data = pd.read_csv(\"data/WHO_life.csv\")\n",
    "X_WHO = WHO_data.drop(columns = [\"Life expectancy \"])\n",
    "y = WHO_data[\"Life expectancy \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd4f6d",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_WHO.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16282345",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Many features from WHO dataset:\n",
    "\n",
    "Regressing to find weights life expectancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47166a1b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_WHO.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4af08a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But let's take a look at a few of these and their correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a98830",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "col_selector = ['Income composition of resources', 'Schooling','Alcohol', ' thinness  1-19 years']\n",
    "subsetX = X_WHO[col_selector]\n",
    "sns.heatmap(subsetX.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144992f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's focus on Schooling and income composite resources (ICR):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7276cad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ Life= w_1*Alcohol + w_2*Polio + w_3*Schooling + w_4*Measles + w_5*ICR + ... $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e6f8e9",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Correlation is very high!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ba4dd4",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "col_selector = ['Income composition of resources', 'Schooling']\n",
    "X_WHO[col_selector].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2498e01d",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our regression: \n",
    "- Y = life expectancy\n",
    "\n",
    "$$ Y - \\sum_{i \\neq 3,5} w_i x_i = w_3 Schooling + w_5 ICR $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c26724a",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Schooling and ICR highly related:\n",
    "\n",
    "- Implies that $w_3$ and $w_5$ introduce too much flexibility.\n",
    "- Maybe could fit almost as well with just $w_3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89056b45",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $w_3$ and $w_5$ are floppy and can become big in either direction to fit data.\n",
    "- Var[$\\textbf{w}$] from $w_3$ and $w_5$ high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69b0e80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Modeling data by linear model w/ multicollinear features:\n",
    "- intoduces high weight variance\n",
    "- unnecessary model complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f36b01",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These considerations are all nice and theoretical:\n",
    "    \n",
    "- how do we actually assess whether model suffers from bias / variance or both?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b09965e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### How to assess model variance: cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43237dcc",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Could get many different training sets:\n",
    "- Train weights $\\textbf{w}$ for each.\n",
    "- Get variance of $\\textbf{w}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb76059",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Semi-equivalently:\n",
    "- Test performance of each model on test set.\n",
    "- Evaluate model performance/variance by looking at average/standard deviation of performance on test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d56a10",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Problem: \n",
    "- likely don't have this much data available to make enough independent training sets large enough to for each model to train on effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a2b769",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Solution: Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6d5c9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So first we created our train / test split: \n",
    "\n",
    "- the **training set** can be used to develop models\n",
    "- can assess variance of a model and average performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53cda9d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"images/traintestsplit.png\"  width = 800/>\n",
    "<center> Splitting up training set </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b2821",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = \"Images/crossval.png\"  width = 800/>\n",
    "<center> Splitting up training set </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee35c4d",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Split up training set into folds:\n",
    "- Training fold\n",
    "- Validation fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67599a49",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For each iteration:\n",
    "    - train a model.\n",
    "    - Test on validation fold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a0ea6",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Effectively sampling multiple training sets:\n",
    "- testing each model performance on different **validation set**.\n",
    "- Good for estimating model performance on average\n",
    "- Good for estimating model variance as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd02b829",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So in the end:\n",
    "- Performance metrics measured on validation\n",
    "- We get average performance metric across all the models for each cross validation iteration.\n",
    "- Get variance of performance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39672d6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note: **validation set** is part of training set:\n",
    "- Not part of true test/hold-out set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be5ba89",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We are often trying out different model types:\n",
    "- OLS with raw features\n",
    "- OLS with collinear features dropped\n",
    "- OLS with polynomial features\n",
    "- Ridge regressor (will see later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de86f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Idea is that we try out different model types / tune models: \n",
    "- assess variance\n",
    "- assess average performance\n",
    "\n",
    "**Use train/validation for this**: \n",
    "- for each model type: estimate model average performance and variance *across different train/validation realizations*\n",
    "\n",
    "True and final evaluation:\n",
    "- Measure performance on tuned model on the test set that has never been seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d0fb52",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = \"Images/cvtuningflow.png\"  width = 800/>\n",
    "<center> Model comparison/selection using cross-validation </center>\n",
    "<center> Best model from cross-validation in test phase</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8a88af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Roughly:\n",
    "- Training data is for building the model;\n",
    "- Validation data is for *tweaking* the model;\n",
    "- Testing data is for evaluating the model on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f699ee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Think of **training** data as what you study for a test\n",
    "- Think of **validation** data is using a practice test (note sometimes called **dev**)\n",
    "- Think of **testing** data as what you use to judge the model\n",
    "    - A **holdout** set is when your test dataset is never used for training (unlike in cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343cb3f1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Selected best model based on:\n",
    "- what worked best on the given validation folds.\n",
    "\n",
    "**Iterative optimization of models based on the train/validation data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402cc6f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ultimately: \n",
    "\n",
    "- want to evaluate our best model class (found by optimizing over the validation sets) \n",
    "- on data that has neither been trained or validated on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9fdbf1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://scikit-learn.org/stable/_images/grid_search_workflow.png)\n",
    "> Image from Scikit-Learn https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df73970",
   "metadata": {},
   "source": [
    "\n",
    "<img src = \"Images/test_phase_afterCV.png\"  width = 800/>\n",
    "<center> Best model from cross-validation in test phase</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a5ed7e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Split data into training data and a holdout test\n",
    "2. Design a model\n",
    "3. Evaluate how well it generalizes with **cross-validation** (only training data)\n",
    "4. Determine if we should adjust model, use cross-validation to evaluate, and repeat\n",
    "5. After iteratively adjusting your model, do a _final_ evaluation with the holdout test set\n",
    "6. DON'T TOUCH THE MODEL!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e957db",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cross validation gives us a way to test statistical robustness of model performance:\n",
    "- evaluate average performance\n",
    "- evaluate model variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b405d95",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But seeing a set of models have high variance:\n",
    "- How to address this problem found in cross-validation trials?\n",
    "- i.e., how do we lower the variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6452054",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Ways to limit/deal with high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7b9508",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Get more data. With enough training data, even with floppy weights it'll get it right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aae30f",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Yeah, but often not possible/easy to get enough data for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d846a64e",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Get rid of columns that exhibit a high degree of collinearity with other columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecf3b38",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Yeah, but did we throw out some useful information for prediction? \n",
    "- ICR and schooling not the same thing.\n",
    "- How many of the collinear columns should we throw away? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea673a95",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Getting rid of columns like this:\n",
    "- Can lower variance\n",
    "- But can also increase bias in an arbitrary, non-optimal way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a679fcd",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Or we could come up with ways to directly limit the variance through the cost function itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88b47f1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The hope is that with this method:\n",
    "- decrease variance\n",
    "- without increasing bias too much\n",
    "\n",
    "Doing this in an optimal and principled way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4426898",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Leakage in cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402f3d4c",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/crossval.png\" width = 500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8734b64",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When you pollute your training fold with your validation fold:\n",
    "\n",
    "- Each cross-validation trial has data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f0bd35",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Validation performance measurements not correct:\n",
    "- Incorrect estimates of average model performance\n",
    "- Incorrect estimates of model variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8ddd6d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Messes up your hyperparameter tuning:\n",
    "- \"Best model\": hyperparameter settings with best average model performance\n",
    "- But it doesn't work well on my test/hold-out set..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a9a8a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b3c81a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data = load_diabetes()\n",
    "\n",
    "print(data.DESCR)\n",
    "\n",
    "df = pd.concat([pd.DataFrame(data.data, columns=data.feature_names),\n",
    "               pd.Series(data.target, name='target')], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff254b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_diabetes(return_X_y=True)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a107733f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "for train_ind, val_ind in KFold().split(X_train2):\n",
    "    \n",
    "    train = X_train2[train_ind, :]\n",
    "    val = X_train2[val_ind, :]\n",
    "    \n",
    "    target_train = y_train2[train_ind]\n",
    "    target_val = y_train2[val_ind]\n",
    "    \n",
    "    ss = StandardScaler().fit(train)\n",
    "    \n",
    "    train_scld = ss.transform(train)\n",
    "    \n",
    "    val_scld = ss.transform(val)\n",
    "    \n",
    "    lr = LinearRegression().fit(train_scld, target_train)\n",
    "    \n",
    "    print(lr.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10600178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91734f45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dplearn",
   "language": "python",
   "name": "dplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
