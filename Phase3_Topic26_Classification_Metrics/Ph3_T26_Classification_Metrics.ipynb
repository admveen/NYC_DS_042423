{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb865ec2",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Classification Metrics\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC Feb 2022\n",
    "<p>Phase 3: Topic 26</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e169a6",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce6780e",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Many classification metrics for evaluating model validation/test set performance:\n",
    "\n",
    "- Changes which model you will pick during hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a01e0b5",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Choice of evaluation metric:\n",
    "- Major impact on how well model serves its intended goals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e006e9f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Scenario: Identifying Fraudulent Credit Card Transactions\n",
    "<center><img src = \"Images/credit_card.png\" width = 400/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f154b22",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "credit_data = pd.read_csv('data/credit_fraud_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4161dfa2",
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    10000 non-null  float64\n",
      " 1   V1      10000 non-null  float64\n",
      " 2   V2      10000 non-null  float64\n",
      " 3   V3      10000 non-null  float64\n",
      " 4   V4      10000 non-null  float64\n",
      " 5   V5      10000 non-null  float64\n",
      " 6   V6      10000 non-null  float64\n",
      " 7   V7      10000 non-null  float64\n",
      " 8   V8      10000 non-null  float64\n",
      " 9   V9      10000 non-null  float64\n",
      " 10  V10     10000 non-null  float64\n",
      " 11  V11     10000 non-null  float64\n",
      " 12  V12     10000 non-null  float64\n",
      " 13  V13     10000 non-null  float64\n",
      " 14  V14     10000 non-null  float64\n",
      " 15  V15     10000 non-null  float64\n",
      " 16  V16     10000 non-null  float64\n",
      " 17  V17     10000 non-null  float64\n",
      " 18  V18     10000 non-null  float64\n",
      " 19  V19     10000 non-null  float64\n",
      " 20  V20     10000 non-null  float64\n",
      " 21  V21     10000 non-null  float64\n",
      " 22  V22     10000 non-null  float64\n",
      " 23  V23     10000 non-null  float64\n",
      " 24  V24     10000 non-null  float64\n",
      " 25  V25     10000 non-null  float64\n",
      " 26  V26     10000 non-null  float64\n",
      " 27  V27     10000 non-null  float64\n",
      " 28  V28     10000 non-null  float64\n",
      " 29  Amount  10000 non-null  float64\n",
      " 30  Class   10000 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "credit_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d10a67",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The dataset contains a bunch of features:\n",
    "- The transaction amount\n",
    "- The relative time of the transaction\n",
    "- V1-V28 are relevant features: product of feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9572360",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Fraud transaction algorithms:\n",
    "- Typically huge number of features \n",
    "- Can create snall combination of features that encompass most variation in the full feature set:\n",
    "    - Principal component analysis (PCA)\n",
    "    - V1-V28 are these combination features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49176b",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Target 'Class':\n",
    "- 1 if the transaction was fraudulent\n",
    "- 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e857f5b",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c53546",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9962\n",
       "1      38\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a536cad",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What have we just learned about our target in our dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3e039",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Run a logistic regression on the credit card fraud data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e90f4e2f",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate data into feature and target DataFrames\n",
    "X = credit_data.drop('Class', axis = 1)\n",
    "y = credit_data['Class']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25,\n",
    "                                                   random_state=1)\n",
    "# Scale the data for modeling\n",
    "cred_scaler = StandardScaler()\n",
    "cred_scaler.fit(X_train)\n",
    "X_train_sc = cred_scaler.transform(X_train)\n",
    "X_test_sc = cred_scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regresssion model with the train data\n",
    "cred_model = LogisticRegression(random_state=42)\n",
    "cred_model.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319ed9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember:\n",
    "- .score(X,y) gets the accuracy of our classification model on predicting y given X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a6caa91",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cred_model.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b9d8e9",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We got 99.88% accuracy! \n",
    "- Our model is good. Right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f1cd4c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Think again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f8b9b5",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Accuracy** = $\\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "- Fraction of correct classifications.\n",
    "- What the `.score()` method calculates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a02b9",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**Class 1 (Fraud) = Our positive class**\n",
    "\n",
    "- TP: True positive\n",
    "- FP: False positive\n",
    "- TN: True negative\n",
    "- FN: False negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b97fee9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Easy way to unpack the TP, TN, FP, FN is using the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd8fb44d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import plot_confusion_matrix #nice function to visualize confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2538d2fd",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2493,    0],\n",
       "       [   3,    4]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions\n",
    "y_pred = cred_model.predict(X_test_sc) \n",
    "# calculate confusion matrix\n",
    "cfmat = confusion_matrix(y_test, y_pred) \n",
    "\n",
    "cfmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50bff038",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEGCAYAAAAT05LOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYs0lEQVR4nO3de7RV5Xnv8e9vbzb3iyJCEFAgJSRIlSiiJicWYyokJx2aNI5ibLWtHi/Fppe0GZp0aKKHNOO0SU80aiVq1TZiya1qI2KCSdEzMICKIBguFUUEg6BGbsK+POePNbcucO+159zstddl/j5jzLHnete8PEsdj+9lvu9URGBmljcNlQ7AzKwSnPzMLJec/Mwsl5z8zCyXnPzMLJf6VDqAYiOGN8b4cU2VDsMy2LB6YKVDsAzeZi8H44CO5Bqzzh4Uu15vTXXsU6sPLI6I2Udyv3KpquQ3flwTyxePq3QYlsGs46ZVOgTL4Jex5IivsfP1Vn65eGyqY5tG//eII75hmVRV8jOzWhC0RlulgzhiTn5mlkkAbdT+5AgnPzPLrA3X/MwsZ4Kg2c1eM8ubAFrd7DWzPHKfn5nlTgCtdbAalJOfmWVW+z1+Tn5mllEQ7vMzs/yJgObaz31OfmaWlWjliKYHVwUnPzPLJIA21/zMLI9c8zOz3Ck85OzkZ2Y5E0Bz1P46yE5+ZpZJIFrrYBF4Jz8zy6wt3Ow1s5xxn5+Z5ZRodZ+fmeVNYSVnJz8zy5kIcTAaKx3GEXPyM7PM2tznZ2Z5UxjwcLPXzHLHAx5mlkMe8DCz3Gr1Q85mljeBaI7aTx21/wvMrFd5wMPMcimQm71mlk8e8DCz3InAj7qYWf4UBjw8vc3McsgDHmaWO4G8mKmZ5ZNrfmaWO4X39jr5mVnuyMvYm1n+FF5dWfujvbVfdzWzXhUh2qIh1VaKpHGSfi7peUlrJf1FUj5c0k8lbUz+Hl10zrWSNklaL2lWUfmpktYk390kqcuqqZOfmWXWGg2pti60AF+MiA8BZwBzJU0BrgGWRMQkYEnymeS7OcCJwGzgVkntVdDbgMuBSck2u6ubO/mZWSaF9fyUait5nYjtEfF0sr8beB4YA5wH3JMcdg9wfrJ/HnB/RByIiM3AJmCGpNHA0IhYFhEB3Ft0Tqfc52dmGWVayXmEpJVFn+dHxPz3XFEaD3wY+CUwKiK2QyFBShqZHDYGeLLotK1JWXOyf3h5SU5+ZpZJ4VGX1KO9OyNieqkDJA0Gfgj8ZUS8VaK7rqMvokR5SU5+ZpZJT87tldREIfF9LyJ+lBT/WtLopNY3GtiRlG8FxhWdPhbYlpSP7aC8JPf5mVlmbTSk2kpJRmTvBJ6PiG8VffUgcEmyfwnwQFH5HEn9JE2gMLCxPGki75Z0RnLNi4vO6ZRrfmaWSWFJqx55yPmjwB8BayStSsq+DHwDWCjpUmALcEHhvrFW0kJgHYWR4rkR0ZqcdxVwNzAAWJRsJTn5mVlmPbGwQUQ8Qcf9dQDndHLOPGBeB+UrgalZ7u/kZ2aZFFZ1qf0eMyc/M8ukML3NyS+XdrzSxD/8xfG8saMJNQSf+sNdfOayne98//3bjuWOG8ewcM0ahh3TSvNB8e0vjWXj6oGoAa664RVO/sgeAL78+Ym8vqOJ1haYevperv76Vhprf9pkzZo+8y2uvHEbjQ3BogXDWfidUZUOqQq55tclSbOBbwONwB0R8Y1y3q+3NPYJLr9uG5NO2s++PQ1cPfsDnHLWbk74wAF2vNLEM0uHMHLMwXeOX/S9YwC4/bH1vLmzD1+5aCI3L9pAQwN85fYXGTSkjQi48X+N5/GHjmLm+W9W6JflW0NDMPfrr3DtnIns3N7EzQ9v5MnFw9iysX+lQ6s6Xc3eqAVlS9/JnLtbgE8CU4ALk7l5Ne+YUS1MOmk/AAMHtzHutw6wc3sTALd/dQyX/t02ip/T3LKhHx/+WKGmd9SIFgYPa2XDswMBGDSkDYDWFmg5qM67f63sJn94H9te7MurW/rR0tzALx44ijNn/abSYVWd9tHeNFs1K2fddQawKSJeiIiDwP0U5ubVlVdf7st/PzeAD56yj2WLhzLifc28/8S3Dzlm4olvs2zxMFpb4NUtfdm4eiCvbWt65/svXziRPzhpKgMGt/GxT7/Zy7/A2h3zvmZe29b3nc87tzcxYnRzBSOqXj2xqkullTO6McDLRZ87nG8n6XJJKyWtfG1X6+FfV7X9exu48bLxXHnDKzQ2BgtuGsXFf7v9PcfNmrOLEaMPcvXsydx23RimTN9LY+O7s2++vuAFFjyzluaDYtUTg3vzJ1iRjmZVRZeTpPKn/R0eabZqVs4+v1Tz7ZJJzvMBpp/cv2b+U2tphhsvG8/HP/sG/+NTv2Hz8/15dUtfrvrEBwF4bXsTc2dN5qaHNzB8ZAtXfu3d2TZ/+XuTGDPxwCHX69s/OPPc37Bs8TBO/Z09vfpbrGDn9iaOPe7dvtoRo5vZ9WpTiTPyKYCWKq/VpVHO5NfZPLyaFwHf+uLxjJt0gN+/4jUAJnzobRauWfvOMRfPmMLNi9Yz7JhW3t4nQPQf2MZT/zWYxj7BCR84wP69Dezb08Axo1pobYHlS4Yy9fS9FfpVtn7VQMZMOMiocQfY9WoTM897k2/MPaHSYVWlam/SplHO5LcCmJTMwXuFwiKEny/j/XrN2uWDWPKD4Uz40H6u+sRkAP7k2m3MOGd3h8e/uauJr1w4ETUU+pW+dPNLALy9r4Gv/vFEmg+K1laY9tE9fPrinR1ew8qvrVXc8pUxfP2+F2hohEfvH85LGzzS+x410KRNo2zJLyJaJF0NLKbwqMtdEbG2i9NqwtTT97J426qSx9y7fN07++8bd5A7n/jVe445+tgWbl60oafDsyOw4rGhrHhsaKXDqGrti5nWurI+5xcRDwMPl/MeZtb7XPMzs9zJuJhp1XLyM7NMAtHS5gEPM8sh9/mZWf6Em71mlkPu8zOz3HLyM7PcCUSrBzzMLI884GFmuRMe8DCzvAonPzPLHy9sYGY55ZqfmeVOBLS2OfmZWQ55tNfMcidws9fMcskDHmaWU/XwVjsnPzPLzM1eM8udwmiv5/aaWQ652WtmueRmr5nlTiAnPzPLpzpo9VL7vZZm1rsCok2ptq5IukvSDknPFZV9VdIrklYl26eKvrtW0iZJ6yXNKio/VdKa5LubJHV5cyc/M8ssQqm2FO4GZndQ/k8RMS3ZHgaQNAWYA5yYnHOrpMbk+NuAy4FJydbRNQ/h5GdmmUWk27q+TiwFXk952/OA+yPiQERsBjYBMySNBoZGxLKICOBe4PyuLtZpn5+kmynRtI+IL6QM2MzqSMa5vSMkrSz6PD8i5qc472pJFwMrgS9GxBvAGODJomO2JmXNyf7h5SWVGvBYWeI7M8urANInv50RMT3jHW4DbkzudCPwTeBPocOlZKJEeUmdJr+IuKf4s6RBEbG3qwuaWf0r50POEfHr9n1J3wX+M/m4FRhXdOhYYFtSPraD8pK67POTdKakdcDzyeeTJd3a1XlmVq/SjfSmGe3t8OqFPrx2nwHaR4IfBOZI6idpAoWBjeURsR3YLemMZJT3YuCBru6T5jm//wvMSm5MRDwr6azUv8TM6k8P1fwkLQBmUugb3ApcD8yUNC25y4vAFQARsVbSQmAd0ALMjYjW5FJXURg5HgAsSraSUj3kHBEvH/bYTGtnx5pZnYuem94WERd2UHxniePnAfM6KF8JTM1y7zTJ72VJHwFCUl/gCyRNYDPLqTqY4pHmOb8rgbkUho5fAaYln80st5Ryq15d1vwiYidwUS/EYma1oq3SARy5NKO9EyU9JOm1ZA7eA5Im9kZwZlaF2p/zS7NVsTTN3vuAhcBo4Djg+8CCcgZlZtWtp6a3VVKa5KeI+NeIaEm2f6MuujvNrNsi5VbFSs3tHZ7s/lzSNcD9FH7OHwA/6YXYzKxaVXmTNo1SAx5Pcei8uSuKvmufc2dmOaQqr9WlUWpu74TeDMTMakQIujl1rZqkmuEhaSowBejfXhYR95YrKDOrcvVc82sn6XoKc++mAA8DnwSeoLBgoJnlUR0kvzSjvZ8DzgFejYg/AU4G+pU1KjOrbvU82ltkf0S0SWqRNBTYAfghZ7O8yraYadVKk/xWSjoK+C6FEeA9wPJyBmVm1a2uR3vbRcSfJbv/LOkRCi8KWV3esMysqtVz8pN0SqnvIuLp8oRkZtWu3mt+3yzxXQAf7+FY2LB6ILOOm9bTlzWznlbPfX4RcXZvBmJmNaIGRnLTSPWQs5nZIZz8zCyPVAeLmTr5mVl2dVDzS7OSsyT9oaTrks/HS5pR/tDMrBop0m/VLM30tluBM4H2V8ztBm4pW0RmVv3qYBn7NM3e0yPiFEnPAETEG8krLM0sr6q8VpdGmuTXLKmR5OdKOpa6eHeTmXVXtTdp00iT/G4CfgyMlDSPwiovf1fWqMysekVORnsj4nuSnqKwrJWA8yPi+bJHZmbVKw81P0nHA/uAh4rLImJLOQMzsyqWh+RH4U1t7S8y6g9MANYDJ5YxLjOrYrno84uI3y7+nKz2ckUnh5uZ1YTMMzwi4mlJp5UjGDOrEXmo+Un666KPDcApwGtli8jMqlteRnuBIUX7LRT6AH9YnnDMrCbUe80vebh5cET8bS/FY2ZVTtTHgEenc3sl9YmIVgrNXDOzd/XQqysl3SVph6TnisqGS/qppI3J36OLvrtW0iZJ6yXNKio/VdKa5LubJHU5sbjUwgbtb2hbJelBSX8k6bPtW9c/y8zqUs+u6nI3MPuwsmuAJRExCViSfEbSFGAOhcfsZgO3Jq1TgNuAy4FJyXb4Nd8jzaouw4FdFN7Z8Wng95K/ZpZXbSm3LkTEUuD1w4rPA+5J9u8Bzi8qvz8iDkTEZmATMEPSaApvlVwWEQHcW3ROp0r1+Y1MRnqf492HnN+JuasLm1n9KnOf36iI2A4QEdsljUzKxwBPFh23NSlrTvYPLy+pVPJrBAZzaNJr5+RnlmfpM8AISSuLPs+PiPndvGtnuahbOapU8tseETekjcrMciLb29t2RsT0jHf4taTRSa1vNLAjKd8KjCs6biywLSkf20F5SaX6/Kp7GVYzq5gyL2P/IHBJsn8J8EBR+RxJ/SRNoDCwsTxpIu+WdEYyyntx0TmdKlXzO6fboZtZfeuhji9JC4CZFJrHW4HrgW8ACyVdCmwBLgCIiLWSFgLrKEy4mJs8jgdwFYWR4wHAomQrqdRLyw8fgTEzA3pueltEXNjJVx1WviJiHjCvg/KVwNQs9/arK80sm2x9flXLyc/MMhH1MSDg5Gdm2bnmZ2Z5VA8LGzj5mVl2Tn5mljs5WszUzOxQrvmZWR65z8/M8snJz8zyyDU/M8ufINVCpdXOyc/MMqmXFxg5+ZlZdk5+ZpZHitrPfk5+ZpaNV3Uxs7xyn5+Z5ZKnt5lZPrnmZ2a5c2QvJ6oaTn5mlp2Tn5nljR9yNrPcUlvtZz8nPzPLxs/5WSlN/dr45o820dQ3aOwTPP6To/jXf3xfpcOyFBoagpsf2cCu7U1cd8nESodTlfyoSwmS7gI+DeyIiEwvE64HzQfEly54P2/va6SxT/Ct/9jEiseG8KunB1U6NOvC+Zft5OWN/Rk4uLXSoVSvOqj5NZTx2ncDs8t4/Son3t7XCECfpqCxKaiD6ZB1b8Tog8w45y0W3Te80qFUNUW6rZqVreYXEUsljS/X9WtBQ0PwncUbOG78QR66+xjWP+NaX7W78mvbuON/j2bg4Dpo15VLQD38n7ycNb9UJF0uaaWklc0cqHQ4PaqtTfzZ707molOnMHnaPk6YvL/SIVkJp3/iLd7c2YdNawZWOpSqp7Z0WzWr+IBHRMwH5gMM1fDa/99JB/a+1cizywZz2tm7eWn9gEqHY52Yctpezjj3LU47Zx19+wUDh7TypZtf4v/8+QmVDq2q+Dk/K2nY8BZaWsTetxrp27+NUz62h4W3jKx0WFbCv/z9aP7l70cDcNKZe/jclTuc+DoSURfNXie/Mhk+qpm/+fYWGhqgoQGWPjSMX/5saKXDMusRrvmVIGkBMBMYIWkrcH1E3Fmu+1Wbzc8PYO65kysdhnXT6mWDWb1scKXDqF5Ofp2LiAvLdW0zqyzX/MwsfwJorf3s5+RnZpnVQ82v4s/5mVkNah/x7WrrgqQXJa2RtErSyqRsuKSfStqY/D266PhrJW2StF7SrCP5CU5+ZpZZD09vOzsipkXE9OTzNcCSiJgELEk+I2kKMAc4kcLU2VslNXb3Nzj5mVk2kWHrnvOAe5L9e4Dzi8rvj4gDEbEZ2ATM6O5NnPzMLBMBao1UG4VH3VYWbZcfdrkAHpX0VNF3oyJiO0Dyt312wBjg5aJztyZl3eIBDzPLTOlneOwsas525KMRsU3SSOCnkn5V6rYdlHW7fuman5ll04PN3ojYlvzdAfyYQjP215JGAyR/dySHbwXGFZ0+FtjW3Z/h5GdmGaUc6e2idihpkKQh7fvAucBzwIPAJclhlwAPJPsPAnMk9ZM0AZgELO/ur3Cz18wy66Hn/EYBP5YEhVx0X0Q8ImkFsFDSpcAW4AKAiFgraSGwDmgB5kZEt5fbdvIzs+x6YFWXiHgBOLmD8l3AOZ2cMw+Yd8Q3x8nPzLIK2kdya5qTn5llV/u5z8nPzLLL8KhL1XLyM7PsnPzMLHcCqPKXE6Xh5GdmmYhws9fMcqqt9qt+Tn5mlo2bvWaWV272mlk+OfmZWf74peVmlkd+e5uZ5ZX7/Mwsn5z8zCx3Amhz8jOz3PGAh5nllZOfmeVOAK21P8XDyc/MMgoIJz8zyyM3e80sdzzaa2a55ZqfmeWSk5+Z5U4EtHb7XeFVw8nPzLJzzc/McsnJz8zyJzzaa2Y5FBB+yNnMcsnT28wsdyL86kozyykPeJhZHoVrfmaWP17M1MzyyAsbmFkeBRB1ML2todIBmFmNiWQx0zRbFyTNlrRe0iZJ1/RC9O9wzc/MMoseaPZKagRuAX4X2AqskPRgRKw74oun4JqfmWXXMzW/GcCmiHghIg4C9wPnlT32RFXV/Hbzxs6fxQ9eqnQcZTAC2FnpICyTev13dsKRXmA3byz+WfxgRMrD+0taWfR5fkTMT/bHAC8XfbcVOP1I40urqpJfRBxb6RjKQdLKiJhe6TgsPf8761xEzO6hS6mjy/fQtbvkZq+ZVcpWYFzR57HAtt66uZOfmVXKCmCSpAmS+gJzgAd76+ZV1eytY/O7PsSqjP+dlVlEtEi6GlgMNAJ3RcTa3rq/og6mqZiZZeVmr5nlkpOfmeWSk18ZVXLqjnWPpLsk7ZD0XKVjsfJy8iuToqk7nwSmABdKmlLZqCyFu4Geeo7NqpiTX/lUdOqOdU9ELAVer3QcVn5OfuXT0dSdMRWKxcwO4+RXPhWdumNmpTn5lU9Fp+6YWWlOfuVT0ak7Zlaak1+ZREQL0D5153lgYW9O3bHukbQAWAZMlrRV0qWVjsnKw9PbzCyXXPMzs1xy8jOzXHLyM7NccvIzs1xy8jOzXHLyqyGSWiWtkvScpO9LGngE17pb0ueS/TtKLbogaaakj3TjHi9Kes9bvjorP+yYPRnv9VVJf5M1RssvJ7/asj8ipkXEVOAgcGXxl8lKMplFxGVdvCh6JpA5+ZlVMye/2vU48FtJreznku4D1khqlPQPklZIWi3pCgAVfEfSOkk/AUa2X0jSLyRNT/ZnS3pa0rOSlkgaTyHJ/lVS6/yYpGMl/TC5xwpJH03OPUbSo5KekXQ7Hc9vPoSk/5D0lKS1ki4/7LtvJrEskXRsUvZ+SY8k5zwu6YM98k/TcscvMKpBkvpQWCfwkaRoBjA1IjYnCeQ3EXGapH7A/5P0KPBhYDLw28AoYB1w12HXPRb4LnBWcq3hEfG6pH8G9kTEPybH3Qf8U0Q8Iel4CrNYPgRcDzwRETdI+p/AIcmsE3+a3GMAsELSDyNiFzAIeDoivijpuuTaV1N4sdCVEbFR0unArcDHu/GP0XLOya+2DJC0Ktl/HLiTQnN0eURsTsrPBU5q788DhgGTgLOABRHRCmyT9FgH1z8DWNp+rYjobF27TwBTpHcqdkMlDUnu8dnk3J9IeiPFb/qCpM8k++OSWHcBbcC/J+X/BvxI0uDk936/6N79UtzD7D2c/GrL/oiYVlyQJIG9xUXAn0fE4sOO+xRdL6mlFMdAobvkzIjY30EsqedLSppJIZGeGRH7JP0C6N/J4ZHc983D/xmYdYf7/OrPYuAqSU0Akj4gaRCwFJiT9AmOBs7u4NxlwO9ImpCcOzwp3w0MKTruUQpNUJLjpiW7S4GLkrJPAkd3Eesw4I0k8X2QQs2zXQPQXnv9PIXm9FvAZkkXJPeQpJO7uIdZh5z86s8dFPrznk5ewnM7hRr+j4GNwBrgNuC/Dj8xIl6j0E/3I0nP8m6z8yHgM+0DHsAXgOnJgMo63h11/hpwlqSnKTS/t3QR6yNAH0mrgRuBJ4u+2wucKOkpCn16NyTlFwGXJvGtxa8GsG7yqi5mlkuu+ZlZLjn5mVkuOfmZWS45+ZlZLjn5mVkuOfmZWS45+ZlZLv1/M+VU23ft2lEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cred_model, \n",
    "                      X_test_sc, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a5a4ba7",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2493 3 0 4\n",
      "[[2493    0]\n",
      " [   3    4]]\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cfmat.flatten()\n",
    "print(tn,fn,fp,tp)\n",
    "\n",
    "print(cfmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb2a3ff5",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cred_model, \n",
    "                      X_test_sc, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b558d831",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9988\n"
     ]
    }
   ],
   "source": [
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dee7bc5",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cred_model.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9532f6",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "My accuracy is great. But is model doing well?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6714350d",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "True positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f14db30",
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true positives\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9011cd0a",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false positives\n",
    "fp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096a9ea",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Model not doing well on fraud detection.\n",
    "\n",
    "But the accuracy is great. What happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac94452e",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Accuracy is not a great metric when:\n",
    "- There's a class imbalance\n",
    "- When we care about the positive detections rate for *each* given class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42d761",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### A better metric (for this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce24cdec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Precision** = $\\frac{TP}{TP + FP}$\n",
    "\n",
    "In this case: \n",
    "- Of the model's prediction of 'fraudulent', how many of those predictions were correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21329363",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac8410ab",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec = tp/(tp+fp)\n",
    "prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bfd99e4",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c811fd6d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the given task of detecting credit card fraud:\n",
    "    \n",
    "Is precision something that the credit card company cares a lot about?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aa328b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Another metric that could be important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75849da",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Recall** = **Sensitivity** = $\\frac{TP}{TP + FN}$\n",
    "\n",
    "Of the actual fraudulent transactions in our data, how many did our model predict as fraudulent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "926080a0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d65fb41",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "rec = tp / (tp + fn)\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3c91e74",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00014453",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this task, is recall an important metric? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54a292",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### A metric balancing both recall and precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6e807b8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34348865",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An $F$-score is a combination of precision and recall, which can be useful when both are important. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71a0d84",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The $F_1$ score is an equal balance of the two using a [harmonic mean](https://en.wikipedia.org/wiki/Harmonic_mean).\n",
    "\n",
    "$$F_1 = 2 \\frac{Precision \\cdot Recall}{Precision + Recall} = \\\\ \\frac{2TP}{2TP + FP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5773d572",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "f1_sc = 2*prec*rec / (prec + rec)\n",
    "print(f1_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5b01f40",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373885b",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Which of these metrics do you think a credit card company would care most about when trying to flag fraudulent transactions to deny?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e70c9b9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `classification_report()`\n",
    "\n",
    "- Summary of the various metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c29d42d2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b3677de",
   "metadata": {
    "cell_style": "center",
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2493\n",
      "           1       1.00      0.57      0.73         7\n",
      "\n",
      "    accuracy                           1.00      2500\n",
      "   macro avg       1.00      0.79      0.86      2500\n",
      "weighted avg       1.00      1.00      1.00      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24270ab4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Get precision/recall/f1-score for each class.\n",
    "- Also prints out class-averaged precision/recall/f-score.\n",
    "- Support: number of instances of each class in test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715bbd13",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Another example: Breast Cancer Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37635889",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950f347",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Load the data and train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d137667a",
   "metadata": {
    "cell_style": "split",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "cancer_data_dict = load_breast_cancer()\n",
    "X_cancer = cancer_data_dict['data']\n",
    "cancer_feature_names = cancer_data_dict[\n",
    "    'feature_names']\n",
    "\n",
    "cancer_features = pd.DataFrame(X_cancer, \n",
    "                               columns = cancer_feature_names)\n",
    "cancer_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce83802",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/fractal_mammogram.png\" width = 600 /></center>\n",
    "<center>Feature engineering mammogram.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59d9404a",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cancer = cancer_data_dict['target']\n",
    "cancer_data_dict['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3909d1",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    " - 0 = malignant\n",
    " - 1 = Benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "259ea64c",
   "metadata": {
    "cell_style": "center",
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "X_train_bc, X_test_bc, y_train_bc, y_test_bc = train_test_split(cancer_features, y_cancer,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2525cb",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Standard scale and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bdd1890",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the data\n",
    "bc_scaler = StandardScaler()\n",
    "bc_scaler.fit(X_train_bc)\n",
    "X_train_sc = bc_scaler.transform(X_train_bc)\n",
    "X_test_sc = bc_scaler.transform(X_test_bc)\n",
    "\n",
    "# Run the model\n",
    "bc_model = LogisticRegression(solver='lbfgs', max_iter=10000,\n",
    "                           random_state=42)\n",
    "bc_model.fit(X_train_sc, y_train_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de2463",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d65977f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = bc_model.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f0ed1a",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Calculate the following for this model:\n",
    "- Use scikit-learn's functions for this\n",
    "\n",
    "- Confusion Matrix\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b3356a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x14c3883bc70>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix(y_test_bc, y_pred)\n",
    "\n",
    "plot_confusion_matrix(bc_model, X_test_sc, y_test_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d11e31b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        54\n",
      "           1       0.99      0.98      0.98        89\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_bc, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ffd25",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Which of these metrics matter for this breast cancer detection problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f10a67",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Which metric to tune model hyperparameters with?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2eb626",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Accuracy: misleading under class imbalance\n",
    "- Precision: when false positives are much worse than false negatives\n",
    "    - Spam detection (false positive sends an important email to spam)\n",
    "- Recall: when false negatives are a lot worse \n",
    "    - X-ray imaging for cancer prediction.  \n",
    "- F-score: both precision and recall important\n",
    "    - RADAR detection of enemy warplanes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b914752",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e282049a",
   "metadata": {
    "cell_style": "center",
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "**Multiclass classification**: more than two possible values for the target. An example:\n",
    "\n",
    "- Classifying iris sub-species based on petal/sepal characteristics.\n",
    "\n",
    "<center><img src = \"Images/iris-dataset.png\" width = 500 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7449a64d",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Same metrics/methods to evaluate our models:\n",
    "- Confusion matrices: number of rows/columns equal to the number of classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2008116",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Metrics (precision/recall):\n",
    "    - choose one class to be the \"positive\" class.\n",
    "    - rest are assigned to the \"negative\" class. \n",
    "    - compute precision/recall for given \"positive\" class.\n",
    "\n",
    "Repeat for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a6de86f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77698db1",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = load_iris()\n",
    "X = data_dict['data']\n",
    "features = pd.DataFrame(X, columns = data_dict['feature_names'])\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32d87940",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data_dict['target']\n",
    "data_dict['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec9985d",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 0 = setosa\n",
    "- 1 = versicolor\n",
    "- 2 = virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d992b269",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# train-test split \n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(features, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "000709a3",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Scale and transform\n",
    "iris_scaler = StandardScaler()\n",
    "X_train_iris_sc = iris_scaler.fit_transform(X_train_iris)\n",
    "X_test_iris_sc = iris_scaler.transform(X_test_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83f84988",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# fit model and get predictions\n",
    "iris_model = LogisticRegression(max_iter = 10000)\n",
    "iris_model.fit(X_train_iris_sc, y_train_iris)\n",
    "y_pred_iris = iris_model.predict(X_test_iris_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a060dc55",
   "metadata": {
    "cell_style": "split",
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x14c3883bb50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(iris_model, X_test_iris_sc, \n",
    "                      y_test_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0be671a",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our confusion matrix for the multiclass iris problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5bd7175",
   "metadata": {
    "cell_style": "center",
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_iris, y_test_iris))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99fe5aa",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some issues with assessing the quality of a model solely on these metrics:\n",
    "- Need to think a little bit more carefully about probabilities and classification thresholds\n",
    "- The reciever operation curve (up next)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
